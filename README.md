Here's a README file based on the provided code files (`quillify_ai.py`, `demo.py`, and `gallery.py`). This README will help you upload the project to GitHub, providing a clear and comprehensive overview of the project.

```markdown
# Quillify.ai

## Introduction
Quillify.ai is an innovative application that allows users to create customized stories, generate images, and compile them into videos with audio. It leverages the power of AI models such as OpenAI and Hugging Face to generate engaging and personalized content.

## Table of Contents
- [Introduction](#introduction)
- [Table of Contents](#table-of-contents)
- [Installation](#installation)
- [Usage](#usage)
- [Features](#features)
- [Dependencies](#dependencies)
- [Configuration](#configuration)
- [Documentation](#documentation)
- [Examples](#examples)
- [Troubleshooting](#troubleshooting)
- [Contributors](#contributors)
- [License](#license)

## Installation
To install and run Quillify.ai locally, follow these steps:

1. Clone the repository:
    ```bash
    git clone https://github.com/yourusername/quillify_ai.git
    cd quillify_ai
    ```

2. Create a virtual environment:
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```

3. Install the required dependencies:
    ```bash
    pip install -r requirements.txt
    ```

4. Run the application:
    ```bash
    streamlit run quillify_ai.py
    ```

## Usage
1. Open the application in your web browser as directed by Streamlit.
2. Enter your OpenAI and Hugging Face API tokens in the sidebar.
3. Input a story prompt, select the desired number of words, voice gender, and image style.
4. Click "Generate Story" to create your customized story.
5. The generated story, images, and video will be displayed and saved to the gallery.

## Features
- **Story Generation**: Generate customized stories based on user prompts.
- **Image Generation**: Create detailed images using AI models.
- **Video Compilation**: Combine images and audio to create a video.
- **Voice Synthesis**: Convert text to speech using different voice options.
- **Gallery**: View and manage generated videos.

## Dependencies
- Streamlit
- Langchain
- HuggingFace Hub
- Spacy
- PIL
- Moviepy
- Pyttsx3
- Mutagen

## Configuration
- **OpenAI API Key**: Required for story generation.
- **Hugging Face API Token**: Required for image generation.

## Documentation
For detailed documentation on using Quillify.ai, refer to the code comments and functions within `quillify_ai.py`, `demo.py`, and `gallery.py`.

## Examples
Here is an example of generating a story:

1. **Input Prompt**: "A young boy with blue eyes embarks on a journey to the moon in a rocket he built with his friends."
2. **Generated Story**: Displays the story text generated by the AI.
3. **Generated Images**: Displays images created from the story text.
4. **Generated Video**: Compiles images and audio into a video.

## Troubleshooting
If you encounter any issues, consider the following steps:
- Ensure that you have entered valid API keys for OpenAI and Hugging Face.
- Check the console for error messages and stack traces.
- Reload the application and try again.

## Contributors
- **Your Name** - [Your GitHub Profile](https://github.com/yourusername)

## License
This project is licensed under the MIT License. See the LICENSE file for more details.
```
