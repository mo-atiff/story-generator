import streamlit as st
from markdowns import ele

from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain, SimpleSequentialChain, SequentialChain

from st_pages import Page, show_pages
from markdowns import ele
import re

import requests
import io
from io import BytesIO
import os
from PIL import Image
from moviepy.editor import *

from IPython.display import display, HTML
import pyttsx3
import math
import shutil
import spacy
import mutagen 
from mutagen.wave import WAVE 

# st.title('Customized User story generator page')
st.markdown("<h1 style='text-align: centre; color: #007BA7;'>Customized User story generator page</h1>", unsafe_allow_html=True)

nlp = spacy.load("en_core_web_sm")

API_URL = "https://api-inference.huggingface.co/models/dataautogpt3/OpenDalleV1.1"
headers = {"Authorization": f"Bearer {st.session_state.huggingtok}"}

def side_bar_view():
    return ele.sides

def extract_adjective_noun_combinations(sentence):
    doc = nlp(sentence.lower())
    adjective_noun_combinations = []
    for token in doc:
        if token.dep_ == "amod" and token.head.pos_ == "NOUN":
            adjective_noun_combinations.append(f"{token.text} {token.head.text}")
    return adjective_noun_combinations


def query(payload):
	response = requests.post(API_URL, headers=headers, json=payload)
	return response.content


def image_generator(tups):
    blob = []
    j = 1
    err_imgs = 0
    with st.status("Creating Images...", expanded=True) as status:
        st.write('Crafting your masterpiece-just a cosmic heartbeat away! üåå‚ú® Just 2-5 mins #ArtistryInProgress')
        for i in tups:
            # st.write(i)
            image_bytes = query({
                "inputs": i,
                # "seed" : 42
            })

            st.write(f"BYTES LEN OF IMAGE - {j} : ", len(image_bytes))

            if len(image_bytes) < 900:
                image_bytes2 = query({
                "inputs": i,
                })

                if len(image_bytes2) > 900:
                    blob.append(image_bytes2)
                    st.write(f"BYTES LEN OF IMAGE - {j} : ", len(image_bytes2))

                else:
                    st.write(f"STILL BYTES LEN OF IMAGE - {j} ARE - {len(image_bytes2)}")
                    err_imgs+=1
            
            
            if len(image_bytes) > 900:
                blob.append(image_bytes)

            elif len(image_bytes) < 900 and len(image_bytes2) < 900:
                err_imgs+=1

            st.write(f"Created Image - {j}")
            j+=1

        status.update(label="Images created sucessfully!", state="complete", expanded=False)

    if err_imgs > 0:
        st.error(f"{err_imgs} error image generated by app")
    return blob



def generate_video_with_audio(temp_images, audio_file_path, duration):
    clip = ImageSequenceClip(temp_images, fps=1)
    slow_clip = clip.speedx(0.13)

    video_clip = slow_clip.to_videofile("temp_output_video.mp4", codec='libx264', fps=1)

    audio_clip = AudioFileClip(audio_file_path)

    vid = VideoFileClip("temp_output_video.mp4")
    vid = vid.subclip(0, duration+2)
    video_clip = vid.set_audio(audio_clip)

    os.makedirs("dir_mp4", exist_ok=True)

    output_video_path = os.path.join("dir_mp4", "output_video.mp4")
    video_clip.write_videofile(output_video_path, codec='libx264', fps=1)

    return output_video_path


def speak_text(text, voice, rate=150):
    engine = pyttsx3.init()

    # print("TEXT : ", text, '\n')
    # print("VOICE : ", voice, '\n')

    engine.setProperty('voice', voice)
    engine.setProperty('rate', rate)


    download_dir = 'dir_mp3'
    os.makedirs(download_dir, exist_ok=True)

    file_path = os.path.join(download_dir, "my_audio.wav") 

    engine.save_to_file(text, file_path)
    engine.runAndWait()
    engine.stop()

    return file_path



side_bar = side_bar_view()
st.sidebar.write(side_bar)

try:
    data = st.session_state.data
    user_data = st.text_area('Add your own creative touch to the story generated by AI! üöÄ‚ú® Personalize the narrative with your imagination. üìö‚úçÔ∏è', value=data)

except Exception as e:
    pass


_, b, _ = st.columns(3)
customized_story = b.button("Generate Customized Story")

if customized_story:
    voices = ["HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Speech\Voices\Tokens\TTS_MS_EN-US_DAVID_11.0", 
                        "HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Speech\Voices\Tokens\TTS_MS_EN-US_ZIRA_11.0"]


    if st.session_state.gens=="Male":
        bytes_path = speak_text(user_data, voices[0])
    else:
        bytes_path = speak_text(user_data, voices[1])


    with open(bytes_path, "rb") as mp3_file:
            aud_bytes = mp3_file.read()

    audio = WAVE(bytes_path)  
    audio_info = audio.info 
    duration_audio = int(audio_info.length)

    st.audio(aud_bytes, format='audio/wav')


    text_for_img = user_data.split('.')

    noun_adj = extract_adjective_noun_combinations(st.session_state.userprompt)
    noun_adj = ' '.join(noun_adj)

    text_for_img = [i+' '+noun_adj+' '+st.session_state.imgstyle+' Very detailed, full HD '  for i in text_for_img]

    binary_img = image_generator(text_for_img)

    temp_images = []
    # shutil.rmtree("dir_png")
    os.makedirs("dir_png", exist_ok=True)

    for i, image_bytes in enumerate(binary_img):
        png_file_path = os.path.join("dir_png", f"image_{i+1}.png")
        with open(png_file_path, "wb") as png_file:
            png_file.write(image_bytes)

        temp_images.append(png_file_path)


    try:
        output_video_path = generate_video_with_audio(temp_images, bytes_path, duration_audio)

        _, container, _ = st.columns([1, 4, 1])
        container.video(data=output_video_path)


    except Exception as e:
        st.write(e)
        st.error('Sorry! Unexpected error occurred please re-generate the story')


    st.markdown("*Video was uploaded to Gallery*")
    st.session_state.upload = True